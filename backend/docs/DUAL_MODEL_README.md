# åŒæ¨¡å‹èŠå¤©ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

åŒæ¨¡å‹èŠå¤©ç³»ç»Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°çš„AIå¯¹è¯è§£å†³æ–¹æ¡ˆï¼Œå®ƒèƒ½å¤Ÿï¼š

1. **å¹¶è¡ŒæŸ¥è¯¢**ï¼šåŒæ—¶å‘Geminiå’Œç¡…åŸºæµåŠ¨æ¨¡å‹æå‡ºç›¸åŒé—®é¢˜
2. **æ™ºèƒ½æ•´åˆ**ï¼šä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹å°†ä¸¤ä¸ªç­”æ¡ˆæ•´åˆæˆæ›´å…¨é¢çš„å›ç­”
3. **é€æ˜å±•ç¤º**ï¼šæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„åŸå§‹å›ç­”å’Œæœ€ç»ˆæ•´åˆç»“æœ

## ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
å¹¶è¡ŒæŸ¥è¯¢èŠ‚ç‚¹
    â”œâ”€â”€ Geminiæ¨¡å‹
    â””â”€â”€ ç¡…åŸºæµåŠ¨æ¨¡å‹
    â†“
ç­”æ¡ˆæ•´åˆèŠ‚ç‚¹
    â†“
æœ€ç»ˆæ•´åˆå›ç­”
```

## ç¯å¢ƒé…ç½®

### å¿…éœ€çš„APIå¯†é’¥

åœ¨ä½¿ç”¨åŒæ¨¡å‹ç³»ç»Ÿä¹‹å‰ï¼Œæ‚¨éœ€è¦é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
# Google Gemini APIå¯†é’¥
GEMINI_API_KEY=your_gemini_api_key_here

# ç¡…åŸºæµåŠ¨APIå¯†é’¥
SILICONFLOW_API_KEY=your_siliconflow_api_key_here
```

### ç¯å¢ƒå˜é‡è®¾ç½®æ–¹æ³•

#### æ–¹æ³•1ï¼šä½¿ç”¨.envæ–‡ä»¶

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º`.env`æ–‡ä»¶ï¼š

```bash
GEMINI_API_KEY=your_gemini_api_key_here
SILICONFLOW_API_KEY=your_siliconflow_api_key_here
```

#### æ–¹æ³•2ï¼šç³»ç»Ÿç¯å¢ƒå˜é‡

**Windows (PowerShell):**
```powershell
$env:GEMINI_API_KEY="your_gemini_api_key_here"
$env:SILICONFLOW_API_KEY="your_siliconflow_api_key_here"
```

**Linux/macOS:**
```bash
export GEMINI_API_KEY="your_gemini_api_key_here"
export SILICONFLOW_API_KEY="your_siliconflow_api_key_here"
```

## ä½¿ç”¨æ–¹æ³•

### 1. è¿è¡Œç¤ºä¾‹è„šæœ¬

```bash
# è¿›å…¥backendç›®å½•
cd backend

# è¿è¡ŒåŒæ¨¡å‹ç¤ºä¾‹
python src/chat/dual_model_example.py
```

### 2. ç¼–ç¨‹æ¥å£ä½¿ç”¨

```python
from src.chat.dual_model_graph import dual_model_graph
from langchain_core.messages import HumanMessage

# åˆ›å»ºåˆå§‹çŠ¶æ€
initial_state = {
    "messages": [HumanMessage(content="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")],
    "processing_stage": "initial"
}

# æ‰§è¡ŒåŒæ¨¡å‹å›¾
result = dual_model_graph.invoke(initial_state)

# è·å–ç»“æœ
final_message = result["messages"][-1]
print("æœ€ç»ˆå›ç­”:", final_message.content)

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
print("Geminiå›ç­”:", result.get("gemini_response"))
print("ç¡…åŸºæµåŠ¨å›ç­”:", result.get("siliconflow_response"))
print("æ•´åˆå›ç­”:", result.get("integrated_response"))
```

### 3. ä¸LangGraphé›†æˆ

```python
from src.chat.dual_model_graph import create_dual_model_graph
from src.chat.state import DualModelState

# åˆ›å»ºè‡ªå®šä¹‰å›¾
graph = create_dual_model_graph()
compiled_graph = graph.compile()

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
config = {
    "configurable": {
        "thread_id": "conversation_1"
    }
}

result = compiled_graph.invoke(initial_state, config=config)
```

## æ–‡ä»¶ç»“æ„

```
src/chat/
â”œâ”€â”€ dual_model_graph.py      # åŒæ¨¡å‹å›¾å®šä¹‰
â”œâ”€â”€ dual_model_example.py    # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ state.py                 # çŠ¶æ€å®šä¹‰ï¼ˆåŒ…å«DualModelStateï¼‰
â”œâ”€â”€ model_factory.py         # æ¨¡å‹å·¥å‚
â”œâ”€â”€ configuration.py         # é…ç½®ç®¡ç†
â””â”€â”€ DUAL_MODEL_README.md     # æœ¬æ–‡æ¡£
```

## æ ¸å¿ƒç»„ä»¶è¯´æ˜

### DualModelState

æ‰©å±•çš„çŠ¶æ€ç±»ï¼ŒåŒ…å«ï¼š

- `messages`: æ¶ˆæ¯å†å²ï¼ˆç»§æ‰¿è‡ªChatStateï¼‰
- `gemini_response`: Geminiæ¨¡å‹çš„å›ç­”
- `siliconflow_response`: ç¡…åŸºæµåŠ¨æ¨¡å‹çš„å›ç­”
- `integrated_response`: æ•´åˆåçš„å›ç­”
- `processing_stage`: å¤„ç†é˜¶æ®µæ ‡è¯†

### å¤„ç†èŠ‚ç‚¹

#### parallel_query_node
- å¹¶è¡Œè°ƒç”¨ä¸¤ä¸ªæ¨¡å‹
- ä½¿ç”¨ThreadPoolExecutoræé«˜æ•ˆç‡
- åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†

#### integration_node
- ä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹æ•´åˆç­”æ¡ˆ
- ç”Ÿæˆç»“æ„åŒ–çš„æœ€ç»ˆå›ç­”
- ä¿ç•™åŸå§‹å›ç­”çš„é€æ˜åº¦

## ç‰¹æ€§ä¼˜åŠ¿

### 1. å¹¶è¡Œå¤„ç†
- åŒæ—¶è°ƒç”¨ä¸¤ä¸ªæ¨¡å‹ï¼Œå‡å°‘æ€»å“åº”æ—¶é—´
- ä½¿ç”¨çº¿ç¨‹æ± ç¡®ä¿é«˜æ•ˆæ‰§è¡Œ

### 2. æ™ºèƒ½æ•´åˆ
- ä¸æ˜¯ç®€å•æ‹¼æ¥ï¼Œè€Œæ˜¯AIé©±åŠ¨çš„æ™ºèƒ½æ•´åˆ
- è¯†åˆ«å†²çªå¹¶æä¾›åˆ¤æ–­
- è¡¥å……é—æ¼ä¿¡æ¯

### 3. é€æ˜åº¦
- æ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„åŸå§‹å›ç­”
- ç”¨æˆ·å¯ä»¥çœ‹åˆ°æ•´åˆè¿‡ç¨‹
- ä¾¿äºæ¯”è¾ƒå’ŒéªŒè¯

### 4. é”™è¯¯å¤„ç†
- å•ä¸ªæ¨¡å‹å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
- è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæ¢å¤æœºåˆ¶
- é…ç½®éªŒè¯ç¡®ä¿ç¯å¢ƒæ­£ç¡®

## ç¤ºä¾‹è¾“å‡º

```
ğŸ¤– åŒæ¨¡å‹æ™ºèƒ½æ•´åˆå›ç­”

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯ä¸€é—¨ç»¼åˆæ€§å­¦ç§‘ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½è¡Œä¸ºçš„è®¡ç®—æœºç³»ç»Ÿ...

---
ğŸ“Š æ¨¡å‹å›ç­”è¯¦æƒ…

**Geminiæ¨¡å‹å›ç­”ï¼š**
äººå·¥æ™ºèƒ½æ˜¯æŒ‡è®©æœºå™¨å…·å¤‡ç±»ä¼¼äººç±»æ™ºèƒ½çš„æŠ€æœ¯...

**ç¡…åŸºæµåŠ¨æ¨¡å‹å›ç­”ï¼š**
äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºåˆ›å»ºæ™ºèƒ½ä»£ç†...
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
   - éªŒè¯APIå¯†é’¥çš„æœ‰æ•ˆæ€§

2. **ç½‘ç»œè¿æ¥é—®é¢˜**
   - ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
   - æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

3. **æ¨¡å‹è°ƒç”¨å¤±è´¥**
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—
   - æ£€æŸ¥APIé…é¢å’Œé™åˆ¶

### è°ƒè¯•æ¨¡å¼

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# è¿è¡ŒåŒæ¨¡å‹å›¾
result = dual_model_graph.invoke(initial_state)
```

## æ‰©å±•å’Œè‡ªå®šä¹‰

### æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†

1. åœ¨`model_factory.py`ä¸­æ·»åŠ æ–°çš„åˆ›å»ºå‡½æ•°
2. æ›´æ–°`dual_model_graph.py`ä¸­çš„æ¨¡å‹è°ƒç”¨é€»è¾‘
3. ä¿®æ”¹é…ç½®éªŒè¯å‡½æ•°

### è‡ªå®šä¹‰æ•´åˆç­–ç•¥

ä¿®æ”¹`integration_node`å‡½æ•°ä¸­çš„æ•´åˆæç¤ºï¼Œå®ç°ä¸åŒçš„æ•´åˆç­–ç•¥ï¼š

```python
integration_prompt = f"""è‡ªå®šä¹‰æ•´åˆæç¤º..."""
```

### æ·»åŠ æ›´å¤šå¤„ç†èŠ‚ç‚¹

```python
# æ·»åŠ é¢„å¤„ç†èŠ‚ç‚¹
graph.add_node("preprocess", preprocess_node)
graph.add_edge(START, "preprocess")
graph.add_edge("preprocess", "parallel_query")
```

## æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘æ§åˆ¶

```python
# è°ƒæ•´çº¿ç¨‹æ± å¤§å°
with ThreadPoolExecutor(max_workers=4) as executor:
    # å¤„ç†é€»è¾‘
```

### ç¼“å­˜æœºåˆ¶

```python
# æ·»åŠ å“åº”ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_model_call(question):
    # æ¨¡å‹è°ƒç”¨é€»è¾‘
```

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›åŒæ¨¡å‹èŠå¤©ç³»ç»Ÿï¼