# =============================================================================
# LangGraph åŒæ¨¡å‹èŠå¤©ä»£ç† - å›¾å®šä¹‰æ¨¡å—
# =============================================================================
# æœ¬æ–‡ä»¶å®šä¹‰äº†åŒæ¨¡å‹èŠå¤©ä»£ç†å›¾ï¼Œå®ç°ï¼š
# 1. å¹¶è¡Œè°ƒç”¨ï¼šåŒæ—¶è¯¢é—®Geminiå’Œç¡…åŸºæµåŠ¨æ¨¡å‹
# 2. ç­”æ¡ˆæ”¶é›†ï¼šæ”¶é›†ä¸¤ä¸ªæ¨¡å‹çš„å›ç­”
# 3. æ™ºèƒ½æ•´åˆï¼šä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹æ•´åˆä¸¤ä¸ªç­”æ¡ˆ
# 4. å¯¹è¯å†å²ï¼šç»´æŠ¤å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
# =============================================================================

# ç³»ç»Ÿæ¨¡å—
import os
from typing import Any, Dict, Optional, List
from concurrent.futures import ThreadPoolExecutor, as_completed

# LangChain æ ¸å¿ƒæ¨¡å—
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig

# LangGraph ç›¸å…³å¯¼å…¥
from langgraph.graph import StateGraph, START, END

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from src.chat.state import ChatState, DualModelState, get_last_user_message
from src.chat.configuration import ChatConfiguration
from src.chat.model_factory import (
    create_gemini_model,
    create_siliconflow_model,
    validate_config
)


# =============================================================================
# é…ç½®éªŒè¯
# =============================================================================

def validate_dual_model_config():
    """ã€éªŒè¯åŒæ¨¡å‹é…ç½®ã€‘
    éªŒè¯Geminiå’Œç¡…åŸºæµåŠ¨çš„APIå¯†é’¥æ˜¯å¦éƒ½å·²é…ç½®ã€‚
    
    Raises:
        ValueError: å½“ä»»ä¸€APIå¯†é’¥æœªé…ç½®æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    gemini_key = os.getenv("GEMINI_API_KEY")
    siliconflow_key = os.getenv("SILICONFLOW_API_KEY")
    
    if not gemini_key:
        raise ValueError("GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼ŒåŒæ¨¡å‹æ¨¡å¼éœ€è¦Gemini APIå¯†é’¥")
    
    if not siliconflow_key:
        raise ValueError("SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼ŒåŒæ¨¡å‹æ¨¡å¼éœ€è¦ç¡…åŸºæµåŠ¨APIå¯†é’¥")


# =============================================================================
# å›¾èŠ‚ç‚¹å®šä¹‰
# =============================================================================

def parallel_query_node(state: DualModelState, config: RunnableConfig = None) -> Dict[str, Any]:
    """ã€å¹¶è¡ŒæŸ¥è¯¢èŠ‚ç‚¹ã€‘
    åŒæ—¶è°ƒç”¨Geminiå’Œç¡…åŸºæµåŠ¨æ¨¡å‹è¯¢é—®åŒä¸€ä¸ªé—®é¢˜ã€‚
    
    Args:
        state: å½“å‰åŒæ¨¡å‹èŠå¤©çŠ¶æ€
        config: LangGraphè¿è¡Œæ—¶é…ç½®
        
    Returns:
        Dict[str, Any]: åŒ…å«ä¸¤ä¸ªæ¨¡å‹å›ç­”çš„çŠ¶æ€æ›´æ–°
    """
    # éªŒè¯é…ç½®
    try:
        validate_dual_model_config()
    except ValueError as e:
        return {
            "messages": [AIMessage(content=f"é…ç½®é”™è¯¯: {str(e)}")],
            "processing_stage": "error"
        }
    
    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    last_message = get_last_user_message(state)
    if not last_message:
        return {
            "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ã€‚")],
            "processing_stage": "error"
        }
    
    # è·å–èŠå¤©é…ç½®
    chat_config = ChatConfiguration.from_runnable_config(config)
    
    # åˆ›å»ºä¸¤ä¸ªæ¨¡å‹å®ä¾‹
    try:
        gemini_model = create_gemini_model(
            config=config,
            temperature=0.7,
            max_retries=2
        )
        
        siliconflow_model = create_siliconflow_model(
            config=config,
            temperature=0.7,
            max_retries=2
        )
    except Exception as e:
        return {
            "messages": [AIMessage(content=f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}")],
            "processing_stage": "error"
        }
    
    # å‡†å¤‡æŸ¥è¯¢æ¶ˆæ¯
    query_messages = state["messages"]
    
    # å¹¶è¡Œè°ƒç”¨ä¸¤ä¸ªæ¨¡å‹
    gemini_response = None
    siliconflow_response = None
    
    def query_gemini():
        try:
            response = gemini_model.invoke(query_messages)
            return "gemini", response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            return "gemini", f"Geminiæ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def query_siliconflow():
        try:
            response = siliconflow_model.invoke(query_messages)
            return "siliconflow", response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            return "siliconflow", f"ç¡…åŸºæµåŠ¨æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}"
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [executor.submit(query_gemini), executor.submit(query_siliconflow)]
        
        for future in as_completed(futures):
            try:
                model_name, response = future.result()
                if model_name == "gemini":
                    gemini_response = response
                elif model_name == "siliconflow":
                    siliconflow_response = response
            except Exception as e:
                # å¦‚æœæŸä¸ªæ¨¡å‹å®Œå…¨å¤±è´¥ï¼Œè®°å½•é”™è¯¯
                if gemini_response is None:
                    gemini_response = f"Geminiæ¨¡å‹æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                if siliconflow_response is None:
                    siliconflow_response = f"ç¡…åŸºæµåŠ¨æ¨¡å‹æ‰§è¡Œå¼‚å¸¸: {str(e)}"
    
    return {
        "gemini_response": gemini_response,
        "siliconflow_response": siliconflow_response,
        "processing_stage": "parallel_query"
    }


def integration_node(state: DualModelState, config: RunnableConfig = None) -> Dict[str, Any]:
    """ã€ç­”æ¡ˆæ•´åˆèŠ‚ç‚¹ã€‘
    ä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹æ•´åˆGeminiå’Œç¡…åŸºæµåŠ¨çš„ä¸¤ä¸ªç­”æ¡ˆã€‚
    
    Args:
        state: å½“å‰åŒæ¨¡å‹èŠå¤©çŠ¶æ€
        config: LangGraphè¿è¡Œæ—¶é…ç½®
        
    Returns:
        Dict[str, Any]: åŒ…å«æ•´åˆç­”æ¡ˆçš„çŠ¶æ€æ›´æ–°
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¤ä¸ªå›ç­”
    if not state.get("gemini_response") or not state.get("siliconflow_response"):
        return {
            "messages": [AIMessage(content="æ— æ³•è·å–åˆ°ä¸¤ä¸ªæ¨¡å‹çš„å›ç­”ï¼Œæ•´åˆå¤±è´¥ã€‚")],
            "processing_stage": "error"
        }
    
    # åˆ›å»ºç¡…åŸºæµåŠ¨æ¨¡å‹ç”¨äºæ•´åˆ
    try:
        integration_model = create_siliconflow_model(
            config=config,
            temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„æ•´åˆç»“æœ
            max_retries=2
        )
    except Exception as e:
        return {
            "messages": [AIMessage(content=f"æ•´åˆæ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}")],
            "processing_stage": "error"
        }
    
    # è·å–åŸå§‹é—®é¢˜
    last_message = get_last_user_message(state)
    original_question = last_message if isinstance(last_message, str) else (last_message.content if last_message else "æœªçŸ¥é—®é¢˜")
    
    # æ„å»ºæ•´åˆæç¤º
    integration_prompt = f"""è¯·ä½ ä½œä¸ºä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ•´åˆä»¥ä¸‹ä¸¤ä¸ªAIæ¨¡å‹å¯¹åŒä¸€é—®é¢˜çš„å›ç­”ï¼Œç”Ÿæˆä¸€ä¸ªæ›´å…¨é¢ã€å‡†ç¡®çš„ç»¼åˆå›ç­”ã€‚

    åŸå§‹é—®é¢˜ï¼š{original_question}

    Geminiæ¨¡å‹çš„å›ç­”ï¼š
    {state['gemini_response']}

    ç¡…åŸºæµåŠ¨æ¨¡å‹çš„å›ç­”ï¼š
    {state['siliconflow_response']}

    è¯·æ•´åˆè¿™ä¸¤ä¸ªå›ç­”ï¼Œæä¾›ä¸€ä¸ªç»¼åˆçš„ã€æ›´å®Œæ•´çš„ç­”æ¡ˆã€‚è¦æ±‚ï¼š
    1. ä¿ç•™ä¸¤ä¸ªå›ç­”ä¸­çš„ä¼˜ç‚¹å’Œå‡†ç¡®ä¿¡æ¯
    2. å¦‚æœæœ‰å†²çªï¼Œè¯·æŒ‡å‡ºå¹¶ç»™å‡ºä½ çš„åˆ¤æ–­
    3. è¡¥å……ä»»ä½•é—æ¼çš„é‡è¦ä¿¡æ¯
    4. ç¡®ä¿å›ç­”é€»è¾‘æ¸…æ™°ã€ç»“æ„å®Œæ•´
    5. ç”¨ä¸­æ–‡å›ç­”

    ç»¼åˆå›ç­”ï¼š"""
    
    # è°ƒç”¨æ•´åˆæ¨¡å‹
    try:
        integration_messages = [HumanMessage(content=integration_prompt)]
        response = integration_model.invoke(integration_messages)
        integrated_content = response.content if hasattr(response, 'content') else str(response)
        
        # æ„å»ºæœ€ç»ˆå›ç­”æ¶ˆæ¯
        final_message = AIMessage(
            content=f"""ğŸ¤– **åŒæ¨¡å‹æ™ºèƒ½æ•´åˆå›ç­”**

            {integrated_content}

            ---
            ğŸ“Š **æ¨¡å‹å›ç­”è¯¦æƒ…**

            **Geminiæ¨¡å‹å›ç­”ï¼š**
            {state['gemini_response']}

            **ç¡…åŸºæµåŠ¨æ¨¡å‹å›ç­”ï¼š**
            {state['siliconflow_response']}"""
        )
        
        return {
            "messages": [final_message],
            "integrated_response": integrated_content,
            "processing_stage": "completed"
        }
        
    except Exception as e:
        return {
            "messages": [AIMessage(content=f"ç­”æ¡ˆæ•´åˆå¤±è´¥: {str(e)}")],
            "processing_stage": "error"
        }


# =============================================================================
# å›¾æ„å»ºä¸ç¼–è¯‘
# =============================================================================

def create_dual_model_graph() -> StateGraph:
    """ã€åˆ›å»ºåŒæ¨¡å‹èŠå¤©å›¾ã€‘
    æ„å»ºå¹¶è¿”å›æ”¯æŒåŒæ¨¡å‹æŸ¥è¯¢å’Œæ•´åˆçš„èŠå¤©å¤„ç†çŠ¶æ€å›¾ã€‚
    
    Returns:
        StateGraph: é…ç½®å¥½çš„åŒæ¨¡å‹èŠå¤©çŠ¶æ€å›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    graph = StateGraph(DualModelState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("parallel_query", parallel_query_node)
    graph.add_node("integration", integration_node)
    
    # è®¾ç½®è¾¹
    graph.add_edge(START, "parallel_query")
    graph.add_edge("parallel_query", "integration")
    graph.add_edge("integration", END)
    
    return graph


# ç¼–è¯‘å›¾å®ä¾‹
dual_model_graph = create_dual_model_graph().compile()

# é»˜è®¤å¯¼å‡º
graph = dual_model_graph


# =============================================================================
# å›¾æ‰§è¡Œæµç¨‹è¯´æ˜
# =============================================================================
"""
ã€åŒæ¨¡å‹èŠå¤©å›¾æ‰§è¡Œæµç¨‹ã€‘

1. å¼€å§‹ (START)
   â†“
2. å¹¶è¡ŒæŸ¥è¯¢èŠ‚ç‚¹ (parallel_query)
   - éªŒè¯åŒæ¨¡å‹é…ç½®
   - åŒæ—¶è°ƒç”¨Geminiå’Œç¡…åŸºæµåŠ¨æ¨¡å‹
   - æ”¶é›†ä¸¤ä¸ªæ¨¡å‹çš„å›ç­”
   â†“
3. æ•´åˆèŠ‚ç‚¹ (integration)
   - ä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹æ•´åˆä¸¤ä¸ªç­”æ¡ˆ
   - ç”Ÿæˆç»¼åˆå›ç­”
   - å±•ç¤ºè¯¦ç»†çš„æ¨¡å‹å›ç­”ä¿¡æ¯
   â†“
4. ç»“æŸ (END)
   - è¿”å›åŒ…å«æ•´åˆç­”æ¡ˆçš„æœ€ç»ˆçŠ¶æ€

ã€ä½¿ç”¨ç¤ºä¾‹ã€‘
```python
from src.chat.dual_model_graph import dual_model_graph
from langchain_core.messages import HumanMessage

# åˆ›å»ºåˆå§‹çŠ¶æ€
initial_state = {
    "messages": [HumanMessage(content="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")]
}

# æ‰§è¡ŒåŒæ¨¡å‹å›¾
result = dual_model_graph.invoke(initial_state)

# è·å–æ•´åˆåçš„å›ç­”
final_response = result["messages"][-1].content
print(final_response)
```

ã€ç‰¹æ€§è¯´æ˜ã€‘
- å¹¶è¡Œå¤„ç†ï¼šåŒæ—¶è°ƒç”¨ä¸¤ä¸ªæ¨¡å‹ï¼Œæé«˜æ•ˆç‡
- æ™ºèƒ½æ•´åˆï¼šä½¿ç”¨AIæ¨¡å‹æ•´åˆç­”æ¡ˆï¼Œè€Œéç®€å•æ‹¼æ¥
- é€æ˜å±•ç¤ºï¼šæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„åŸå§‹å›ç­”
- é”™è¯¯å¤„ç†ï¼šåŒ…å«å®Œæ•´çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- é…ç½®éªŒè¯ï¼šç¡®ä¿åŒæ¨¡å‹ç¯å¢ƒæ­£ç¡®é…ç½®
"""