#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæ¨¡å‹é—®ç­”åŠŸèƒ½æµ‹è¯•è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰

æœ¬è„šæœ¬ç”¨äºæµ‹è¯•æ–°å®ç°çš„åŒæ¨¡å‹é—®ç­”åŠŸèƒ½ï¼ŒéªŒè¯ï¼š
1. åŒæ¨¡å‹å›¾çš„æ­£ç¡®æ‰§è¡Œ
2. Geminiå’Œç¡…åŸºæµåŠ¨æ¨¡å‹çš„å¹¶è¡Œè°ƒç”¨
3. å›ç­”æ•´åˆåŠŸèƒ½
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… å·²åŠ è½½.envæ–‡ä»¶")
except ImportError:
    print("âš ï¸  python-dotenvæœªå®‰è£…ï¼Œå°è¯•æ‰‹åŠ¨åŠ è½½.envæ–‡ä»¶")
    # æ‰‹åŠ¨åŠ è½½.envæ–‡ä»¶
    env_file = project_root / '.env'
    if env_file.exists():
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()
        print("âœ… æ‰‹åŠ¨åŠ è½½.envæ–‡ä»¶å®Œæˆ")
    else:
        print("âŒ .envæ–‡ä»¶ä¸å­˜åœ¨")

from langchain_core.messages import HumanMessage
from src.chat.graph import dual_model_chat_graph
from src.chat.state import DualModelState


async def test_simple_dual_model():
    """ç®€åŒ–çš„åŒæ¨¡å‹æµ‹è¯•"""
    print("\n=== ç®€åŒ–åŒæ¨¡å‹æµ‹è¯• ===")
    
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        print("æ£€æŸ¥ç¯å¢ƒå˜é‡...")
        gemini_key = os.getenv('GEMINI_API_KEY')
        siliconflow_key = os.getenv('SILICONFLOW_API_KEY')
        
        print(f"GEMINI_API_KEY: {'å·²è®¾ç½®' if gemini_key else 'æœªè®¾ç½®'}")
        print(f"SILICONFLOW_API_KEY: {'å·²è®¾ç½®' if siliconflow_key else 'æœªè®¾ç½®'}")
        
        if not gemini_key or not siliconflow_key:
            print("âŒ ç¼ºå°‘å¿…è¦çš„APIå¯†é’¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®")
            return False
        
        # åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
        test_message = "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
        messages = [HumanMessage(content=test_message)]
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = DualModelState(
            messages=messages,
            processing_stage="initial",
            gemini_response=None,
            siliconflow_response=None,
            integrated_response=None
        )
        
        print(f"\nç”¨æˆ·é—®é¢˜: {test_message}")
        print("å¼€å§‹æ‰§è¡ŒåŒæ¨¡å‹é—®ç­”...")
        
        # æ‰§è¡ŒåŒæ¨¡å‹é—®ç­”å›¾
        result = await dual_model_chat_graph.ainvoke(initial_state)
        
        # è¾“å‡ºç»“æœ
        print("\n=== æ‰§è¡Œç»“æœ ===")
        print(f"å¤„ç†é˜¶æ®µ: {result.get('processing_stage', 'unknown')}")
        
        gemini_resp = result.get('gemini_response', 'æ— å›ç­”')
        siliconflow_resp = result.get('siliconflow_response', 'æ— å›ç­”')
        integrated_resp = result.get('integrated_response', 'æ•´åˆå¤±è´¥')
        
        print(f"\nã€Geminiæ¨¡å‹å›ç­”ã€‘: {gemini_resp[:100]}{'...' if len(gemini_resp) > 100 else ''}")
        print(f"\nã€ç¡…åŸºæµåŠ¨æ¨¡å‹å›ç­”ã€‘: {siliconflow_resp[:100]}{'...' if len(siliconflow_resp) > 100 else ''}")
        print(f"\nã€æ•´åˆåçš„æœ€ç»ˆå›ç­”ã€‘: {integrated_resp[:100]}{'...' if len(integrated_resp) > 100 else ''}")
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if result.get('processing_stage') == 'completed':
            print("\nâœ… åŒæ¨¡å‹é—®ç­”æµ‹è¯•æˆåŠŸï¼")
            return True
        else:
            print("\nâŒ åŒæ¨¡å‹é—®ç­”æµ‹è¯•å¤±è´¥ï¼")
            print(f"é”™è¯¯è¯¦æƒ…: {result}")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_individual_models():
    """æµ‹è¯•å•ä¸ªæ¨¡å‹è°ƒç”¨"""
    print("\n=== æµ‹è¯•å•ä¸ªæ¨¡å‹è°ƒç”¨ ===")
    
    try:
        from src.shared.model_factory import create_gemini_model, create_siliconflow_model
        
        # æµ‹è¯•Geminiæ¨¡å‹
        print("\næµ‹è¯•Geminiæ¨¡å‹...")
        try:
            gemini_model = create_gemini_model(temperature=0.7)
            gemini_response = gemini_model.invoke([HumanMessage(content="ä½ å¥½")])
            print(f"Geminiå›ç­”: {gemini_response.content[:50]}...")
            print("âœ… Geminiæ¨¡å‹æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Geminiæ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•ç¡…åŸºæµåŠ¨æ¨¡å‹
        print("\næµ‹è¯•ç¡…åŸºæµåŠ¨æ¨¡å‹...")
        try:
            siliconflow_model = create_siliconflow_model(temperature=0.7)
            siliconflow_response = siliconflow_model.invoke([HumanMessage(content="ä½ å¥½")])
            print(f"ç¡…åŸºæµåŠ¨å›ç­”: {siliconflow_response.content[:50]}...")
            print("âœ… ç¡…åŸºæµåŠ¨æ¨¡å‹æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç¡…åŸºæµåŠ¨æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹å¯¼å…¥å¤±è´¥: {str(e)}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åŒæ¨¡å‹é—®ç­”åŠŸèƒ½æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰")
    print("=" * 50)
    
    # æµ‹è¯•å•ä¸ªæ¨¡å‹
    await test_individual_models()
    
    # æµ‹è¯•åŒæ¨¡å‹å›¾
    result = await test_simple_dual_model()
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    if result:
        print("ğŸ‰ åŒæ¨¡å‹é—®ç­”åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œå®ç°")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())